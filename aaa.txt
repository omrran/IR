import re
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize


# emails regEX [^@]+@[^@]+\.[^@]+
# phones regEX (\d{3}[-\.\s]??\d{3}[-\.\s]??\d{4}|\(\d{3}\)\s*\d{3}[-\.\s]??\d{4}|\d{3}[-\.\s]??\d{4})
# dates regEX ^([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])(\.|-|/)([1-9]|0[1-9]|1[0-2])(\.|-|/)([0-9][0-9]|19[0-9][0-9]|20[0-9][0-9])$|^([0-9][0-9]|19[0-9][0-9]|20[0-9][0-9])(\.|-|/)([1-9]|0[1-9]|1[0-2])(\.|-|/)([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])$

def build_vec_mod():
    # read stop words
    f = open("stop words.txt", "r")
    content = f.read()
    f.close()
    stop_words = re.findall("\S+", content)
    print(stop_words)
    # read files in corpus Folder
    tokines = []  # contait all tokines for all docs
    clean_data = []  # contain all tokines for current docs
    diction = {}
    vectors = {"t": [0]}
    f1 = open("result.txt", "w")
    for x in range(1, 424):
        f = open("corpus/{}.txt".format(x), "r")
        t = f.read()
        f.close()
        tokenized_word = word_tokenize(t)

        # remove stop words
        for w in tokenized_word:
            if w not in stop_words:
                clean_data.append(w)
                tokines.append(w)

        temp_dic = {}
        for y in clean_data:
            temp_dic.update({y: clean_data.count(y)})

        diction.update({x: temp_dic})
        clean_data.clear()

    temp_vec = []
    # for t in tokines:
    keys = []
    for d in range(1, 424):
        # temp_vec.append(diction[d].get(t))
        # print(diction.get(d))
        keys = list(diction.get(d).keys())
        print(keys)
        # term = ""
        # for t in tokines:
        #     term = t
        #     if t not in keys:
        #         temp_vec.append(0)
        #     else:
        #         temp_vec.append(1)
        # vectors.update({term: temp_vec})

        # f1.write(str(diction.get(d)))
        # f1.write("\n\n")

        # print(t+" "+str(d))

    # f1.write(str(diction))
    f1.close()
    print(temp_vec)
    # print(len(tokines))
    # print(clean_data)
    # print(diction)
